{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyimagesearch.io import HDF5DatasetWriter\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "imagePaths = list(paths.list_images(\"datasets/animals\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(imagePaths)\n",
    "labels = [p.split(os.path.sep)[-2] for p in imagePaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7), \n",
    "                            'datasets/animals/hdf5/features.hdf5',\n",
    "                           dataKey='features',\n",
    "                           bufSize=1000)\n",
    "dataset.storeClassLabels(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   0% |                                    | ETA:  --:--:--\r"
     ]
    }
   ],
   "source": [
    "widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=len(imagePaths), widgets=widgets).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100% |#####################################| Time: 0:00:39\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0, len(imagePaths), bs):\n",
    "    batchPaths = imagePaths[i:i + bs]\n",
    "    batchLabels = labels[i:i + bs]\n",
    "    batchImages = []\n",
    "    for (j, imagePath) in enumerate(batchPaths):\n",
    "        image = load_img(imagePath, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "        batchImages.append(image)\n",
    "    batchImages = np.vstack(batchImages)\n",
    "    features = model.predict(batchImages, batch_size=bs)\n",
    "    features = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "    dataset.add(features, batchLabels)\n",
    "    pbar.update(i)\n",
    "        \n",
    "dataset.close()\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
